{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling with BERTopic\n",
    "\n",
    "In this notebook, I will show you how to use BERTopic to perform topic modeling on a dataset. BERTopic is a topic modeling technique that leverages BERT embeddings to create dense clusters allowing for easily interpretable topics.\n",
    "\n",
    "The steps we will take are as follows:\n",
    "1. Load the data\n",
    "2. Preprocess the data (Can be done, skipped for this notebook)\n",
    "3. Create topics with BERTopic\n",
    "4. Visualize the topics\n",
    "5. Assign topics to new documents\n",
    "\n",
    "*Note: This notebook is based on the [official BERTopic documentation](https://github.com/MaartenGr/BERTopic)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Loading the data](#1)\n",
    "\n",
    "Data Source: [Emotions](https://www.kaggle.com/datasets/nelgiriyewithana/emotions)\n",
    "\n",
    "Data description:\n",
    "The \"Emotions\" dataset – a collection of English Twitter messages meticulously annotated with six fundamental emotions: anger, fear, joy, love, sadness, and surprise. This dataset serves as a valuable resource for understanding and analyzing the diverse spectrum of emotions expressed in short-form text on social media.\n",
    "\n",
    "Each entry in this dataset consists of a text segment representing a Twitter message and a corresponding label indicating the predominant emotion conveyed. The emotions are classified into six categories:\n",
    "0. sadness\n",
    "1. joy\n",
    "2. love\n",
    "3. anger\n",
    "4. fear\n",
    "5. surprise\n",
    "Whether you're interested in sentiment analysis, emotion classification, or text mining, this dataset provides a rich foundation for exploring the nuanced emotional landscape within the realm of social media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i just feel really helpless and heavy hearted</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ive enjoyed being able to slouch about relax a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i gave up my internship with the dmrg and am f...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i dont know i feel so lost</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am a kindergarten teacher and i am thoroughl...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0      i just feel really helpless and heavy hearted      4\n",
       "1  ive enjoyed being able to slouch about relax a...      0\n",
       "2  i gave up my internship with the dmrg and am f...      4\n",
       "3                         i dont know i feel so lost      0\n",
       "4  i am a kindergarten teacher and i am thoroughl...      4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_data = pd.read_csv('data/text.csv', index_col=0)\n",
    "emotions_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets in the dataset: 416809\n"
     ]
    }
   ],
   "source": [
    "# number of tweets in the dataset\n",
    "print('Number of tweets in the dataset:', emotions_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of a tweet: 178\n",
      "Min length of a tweet: 1\n",
      "Average length of a tweet: 19.0\n"
     ]
    }
   ],
   "source": [
    "# lenghts of tweets\n",
    "emotions_data['length'] = emotions_data['text'].apply(lambda x : len(x.split()))\n",
    "\n",
    "# max length of a tweet\n",
    "print('Max length of a tweet:', emotions_data['length'].max())\n",
    "\n",
    "# min length of a tweet\n",
    "print('Min length of a tweet:', emotions_data['length'].min())\n",
    "\n",
    "# average length of a tweet\n",
    "print('Average length of a tweet:', emotions_data['length'].mean().round(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. [Preprocessing the data](#2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# possible preprocessing steps\n",
    "# import re\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# # Download NLTK resources\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# def preprocess(text):\n",
    "#     text = re.sub(r'\\W', ' ', text.lower())\n",
    "#     words = text.split()\n",
    "#     words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "#     return ' '.join(words)\n",
    "\n",
    "# emotions_data['text'] = emotions_data['text'].apply(preprocess)\n",
    "\n",
    "# not necessary for bertopic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. [Creating topics with BERTopic](#3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\projects\\ai_challenge\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-06-29 17:49:30,147 - BERTopic - Embedding - Transforming documents to embeddings.\n",
      "Batches: 100%|██████████| 13026/13026 [2:59:05<00:00,  1.21it/s]     \n",
      "2024-06-29 20:50:14,386 - BERTopic - Embedding - Completed ✓\n",
      "2024-06-29 20:50:14,386 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-06-29 20:59:35,610 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-06-29 20:59:35,635 - BERTopic - Cluster - Start clustering the reduced embeddings\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "topic_model = BERTopic(language=\"multilingual\", calculate_probabilities=True, verbose=True, )\n",
    "topics, probs = topic_model.fit_transform(emotions_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = topic_model.get_topic_info()\n",
    "display(freq.head(5))\n",
    "\n",
    "topic_model.get_topic(0)  # Select the most frequent topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 [Visualizing the topics](#4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_hierarchy(top_n_topics=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart(top_n_topics=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. [Assigning topics to new documents](#5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"I feel so happy today\"\n",
    "topic_model.transform(test_text)\n",
    "\n",
    "topic_model.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
